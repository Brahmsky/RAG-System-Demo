# RAG_demo å›¢é˜Ÿå¼€å‘è€…æ–‡æ¡£ ğŸš€

## ğŸ†• v2.0 æ¶æ„é‡æ„è¯´æ˜ (2025-10-11)

**é‡è¦**: æœ¬é¡¹ç›®å·²å®Œæˆæ¨¡å—åŒ–é‡æ„ï¼Œç›®å½•ç»“æ„æœ‰é‡å¤§å˜åŒ–ï¼

### ä¸»è¦å˜æ›´
- ğŸ“ **ç›®å½•é‡ç»„**: `rag_system/neo/` â†’ `rag_system/graph/`
- ğŸ—ï¸ **æ¨¡å—åˆ†å±‚**: æ–°å¢ `core/`, `text/`, `generation/`, `utils/` åˆ†å±‚
- ğŸ”§ **å¯¼å…¥è·¯å¾„**: æ‰€æœ‰å¯¼å…¥å·²æ›´æ–°ä¸ºæ–°è·¯å¾„
- ğŸ“ **è¯¦ç»†è¯´æ˜**: è§ `REFACTORING_CHANGELOG.md` å’Œ `HANDOVER_DOCUMENT.md`

### å¿«é€Ÿè¿ç§»æŒ‡å—
```python
# âŒ æ—§çš„å¯¼å…¥æ–¹å¼
from rag_system.config import RAGConfig
from rag_system.neo.Data2Neo4j import Data2Neo4j

# âœ… æ–°çš„å¯¼å…¥æ–¹å¼
from rag_system.core.config import RAGConfig
from rag_system.graph.Data2Neo4j import Data2Neo4j
```

---

## ğŸ“‹ é¡¹ç›®æ¦‚è§ˆ

è¿™æ˜¯ä¸€ä¸ªåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œé›†æˆäº†**æ–‡æœ¬æ£€ç´¢**å’Œ**çŸ¥è¯†å›¾è°±**ä¸¤ç§æ•°æ®æºï¼Œæ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥å’Œå¤šè¯­è¨€å¤„ç†ã€‚é¡¹ç›®é‡‡ç”¨**æ¨¡å—åŒ–åˆ†å±‚æ¶æ„**è®¾è®¡ï¼Œæ˜“äºæ‰©å±•å’Œæµ‹è¯•ã€‚

### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- **å¤šæ¨¡å¼æ£€ç´¢**: æ–‡æœ¬æ£€ç´¢ï¼ˆå‘é‡+å…³é”®è¯+æ··åˆï¼‰ + çŸ¥è¯†å›¾è°±æ£€ç´¢
- **åµŒå…¥å’Œå›ç­”åŒè·¯ç”±**ï¼šåµŒå…¥é‡‡ç”¨gemini apiï¼Œé—®ç­”å’Œllmå¤„ç†é‡‡ç”¨DeepSeek api
- **å¤šè¯­è¨€æ”¯æŒ**: ä¸­è‹±æ–‡æ™ºèƒ½åˆ†è¯å’Œå¤„ç†
- **æ™ºèƒ½é‡æ’åº**: Cross-Encoderæ¨¡å‹ä¼˜åŒ–ç»“æœç›¸å…³æ€§
- **ä¸Šä¸‹æ–‡å‹ç¼©**: å‡å°‘tokenæ¶ˆè€—ï¼Œæå‡ç”Ÿæˆè´¨é‡
- **æŸ¥è¯¢æ‰©å±•**: LLMç”Ÿæˆå¤šæŸ¥è¯¢æå‡å¬å›ç‡
- **æŒä¹…åŒ–å­˜å‚¨**: ChromaDB + Neo4jåŒæ•°æ®åº“æ¶æ„

## é¡¹ç›®å¯åŠ¨æ–¹å¼ï¼š

- æ ¹ç›®å½•ä¸‹è¿è¡Œ```python main.py```

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„å›¾
```mermaid
graph TB
    A[ç”¨æˆ·æŸ¥è¯¢] --> B[RAGSystem]
    B --> C[æ–‡æœ¬æ£€ç´¢è·¯å¾„]
    B --> D[å›¾è°±æ£€ç´¢è·¯å¾„]
    
    C --> E[Retriever]
    E --> F[å‘é‡æ£€ç´¢ Embedder]
    E --> G[å…³é”®è¯æ£€ç´¢ BM25]
    E --> H[å¤šæŸ¥è¯¢æ‰©å±• MultiqueryGenerator]
    
    F --> I[Rerankeré‡æ’åº]
    G --> I
    H --> I
    I --> J[Compressorå‹ç¼©]
    
    D --> K[Neo4jå›¾è°±]
    K --> L[CypheræŸ¥è¯¢ç”Ÿæˆ]
    
    J --> M[Generatorç”Ÿæˆå™¨]
    L --> M
    M --> N[æœ€ç»ˆç­”æ¡ˆ]
    
    O[çŸ¥è¯†åº“æ–‡æ¡£] --> P[TextProcessor]
    P --> Q[ChromaDBå­˜å‚¨]
    P --> R[Data2Neo4jå›¾è°±æ„å»º]
    R --> K
```

### æ¨¡å—ä¾èµ–å…³ç³»
```mermaid
graph LR
    A[RAGSystem] --> B[Database]
    A --> C[Retriever]
    A --> D[Reranker]
    A --> E[Compressor]
    A --> F[Generator]
    A --> G[Data2Neo4j]
    
    C --> H[Embedder]
    C --> I[MultiqueryGenerator]
    
    B --> J[ChromaDB]
    G --> K[Neo4j]
    
    L[TextProcessor] --> M[SpacyTextSplitter]
    L --> N[smart_tokenize]
```

## ğŸ“ é¡¹ç›®ç»“æ„è¯¦è§£

```
RAG_demo/
â”œâ”€â”€ Knowledgebase/              # ğŸ“š çŸ¥è¯†åº“æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ Alan Turing.md         # ç¤ºä¾‹æ–‡æ¡£
â”‚   â”œâ”€â”€ biology_knowledge.md   
â”‚   â””â”€â”€ ...
â”œâ”€â”€ rag_system/                 # ğŸ”§ æ ¸å¿ƒç³»ç»Ÿæ¨¡å—
â”‚   â”œâ”€â”€ config.py              # âš™ï¸ é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ rag_system.py          # ğŸ¯ ä¸»ç³»ç»Ÿç±»ï¼ˆå…¥å£ç‚¹ï¼‰
â”‚   â”œâ”€â”€ database.py            # ğŸ’¾ ChromaDBæ•°æ®åº“ç®¡ç†
â”‚   â”œâ”€â”€ retriever.py           # ğŸ” æ£€ç´¢å™¨ï¼ˆæ–‡æœ¬æ£€ç´¢æ ¸å¿ƒï¼‰
â”‚   â”œâ”€â”€ reranker.py            # ğŸ“Š é‡æ’åºå™¨
â”‚   â”œâ”€â”€ compressor.py          # ğŸ—œï¸ ä¸Šä¸‹æ–‡å‹ç¼©å™¨
â”‚   â”œâ”€â”€ generator.py           # ğŸ¤– ç­”æ¡ˆç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ embedder.py            # ğŸ§  å‘é‡åµŒå…¥å™¨
â”‚   â”œâ”€â”€ multiquery_generator.py # ğŸ”„ å¤šæŸ¥è¯¢ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ query_expander.py      # ğŸ“ˆ æŸ¥è¯¢æ‰©å±•æŠ½è±¡æ¥å£
â”‚   â”œâ”€â”€ text_utils.py          # ğŸ“ æ–‡æœ¬å¤„ç†å·¥å…·
â”‚   â”œâ”€â”€ smart_tokenize.py      # âœ‚ï¸ æ™ºèƒ½åˆ†è¯å™¨
â”‚   â””â”€â”€ neo/                   # ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±æ¨¡å—
â”‚       â”œâ”€â”€ Data2Neo4j.py      # å›¾è°±æ„å»ºä¸æŸ¥è¯¢
â”‚       â””â”€â”€ data_structure.py  # å›¾è°±æ•°æ®ç»“æ„å®šä¹‰
â”œâ”€â”€ main.py                     # ğŸš€ ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ requirements.txt            # ğŸ“¦ ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                   # ğŸ“– é¡¹ç›®æ–‡æ¡£
```

## ğŸ”§ æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. RAGSystem (rag_system.py) - ç³»ç»Ÿä¸»å…¥å£
**èŒè´£**: ç³»ç»Ÿæ€»æ§åˆ¶å™¨ï¼Œç®¡ç†æ‰€æœ‰å­æ¨¡å—çš„åˆå§‹åŒ–å’Œåè°ƒ

**å…³é”®æ–¹æ³•**:
- `add_corpus()`: æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
- `remove_corpus()`: åˆ é™¤æ–‡æ¡£
- `query()`: ç»Ÿä¸€æŸ¥è¯¢æ¥å£ï¼Œæ”¯æŒå¤šç§æ£€ç´¢æ¨¡å¼

**æ£€ç´¢æ¨¡å¼**:
- `vector`: çº¯å‘é‡æ£€ç´¢
- `keyword`: çº¯å…³é”®è¯æ£€ç´¢ï¼ˆBM25ï¼‰
- `text_hybrid`: æ–‡æœ¬æ··åˆæ£€ç´¢ï¼ˆå‘é‡+BM25+RRFèåˆï¼‰
- `expand`: å¤šæŸ¥è¯¢æ‰©å±•æ£€ç´¢
- `graph`: çº¯å›¾è°±æ£€ç´¢
- `hybrid`: **é»˜è®¤æ¨¡å¼**ï¼Œæ–‡æœ¬+å›¾è°±æ··åˆæ£€ç´¢

### 2. Retriever (retriever.py) - æ–‡æœ¬æ£€ç´¢æ ¸å¿ƒ
**èŒè´£**: å®ç°å¤šç§æ–‡æœ¬æ£€ç´¢ç­–ç•¥å’Œç»“æœèåˆ

**æ ¸å¿ƒç®—æ³•**:
- **RRF (Reciprocal Rank Fusion)**: `reciprocal_rank_fusion()` 
  - èåˆå¤šä¸ªæ£€ç´¢ç»“æœåˆ—è¡¨
  - å…¬å¼: `score = Î£(1/(rank + k))`, k=60ä¸ºå¹³æ»‘å‚æ•°

**å…³é”®ç»„ä»¶**:
- ä¾èµ–æ³¨å…¥ `QueryExpander` æ¥å£å®ç°æŸ¥è¯¢æ‰©å±•
- æ”¯æŒsource_filteræŒ‰æ–‡æ¡£è¿‡æ»¤æ£€ç´¢ç»“æœ

### 3. Data2Neo4j (neo/Data2Neo4j.py) - å›¾è°±æ„å»ºä¸æŸ¥è¯¢
**èŒè´£**: æ–‡æœ¬åˆ°çŸ¥è¯†å›¾è°±çš„è½¬æ¢ï¼Œä»¥åŠå›¾è°±æŸ¥è¯¢

**ä¸‰æ­¥æµæ°´çº¿æ¶æ„**:
1. **ç²—æå–**: `_extract_raw_triples()` - æå–(ä¸»ä½“,å…³ç³»,å®¢ä½“)ä¸‰å…ƒç»„
2. **ç»“æ„åŒ–**: `_structure_and_disambiguate_graph()` - è½¬æ¢ä¸ºJSONæ ¼å¼å¹¶æ¶ˆæ­§
3. **å…¥åº“**: `_graph2neo4j()` - å†™å…¥Neo4jæ•°æ®åº“

**æŸ¥è¯¢æµç¨‹**:
1. **Schemaæ£€ç´¢**: `_retrieve_relevant_schema()` - æ ¹æ®é—®é¢˜æ£€ç´¢ç›¸å…³èŠ‚ç‚¹/å…³ç³»
2. **Cypherç”Ÿæˆ**: åŸºäºSchemaç”ŸæˆæŸ¥è¯¢è¯­å¥
3. **æ‰§è¡ŒæŸ¥è¯¢**: è¿”å›ç»“æ„åŒ–ç»“æœ

**åå¤„ç†ä¼˜åŒ–**:
- `after_processing()`: å®ä½“åˆå¹¶ï¼Œè§£å†³é‡å¤èŠ‚ç‚¹é—®é¢˜
- `_llm_get_merge_mapping()`: ä½¿ç”¨Function Callingè¯†åˆ«é‡å¤å®ä½“
- `_execute_merge_operations()`: ä½¿ç”¨APOCæ’ä»¶å®‰å…¨åˆå¹¶èŠ‚ç‚¹

### 4. TextProcessor (text_utils.py) - æ–‡æœ¬å¤„ç†
**èŒè´£**: æ–‡ä»¶è¯»å–å’Œæ–‡æœ¬åˆ†å—

**æ”¯æŒæ ¼å¼**: .txt, .md, .docx
**åˆ†å—ç­–ç•¥**: 
- ä½¿ç”¨ `SpacyTextSplitter` åŸºäºè¯­è¨€æ¨¡å‹åˆ†å—
- é»˜è®¤ chunk_size=256, overlap=25

### 5. Database (database.py) - æ•°æ®åº“ç®¡ç†
**èŒè´£**: ChromaDBå’ŒBM25ç´¢å¼•ç®¡ç†

**æ ¸å¿ƒåŠŸèƒ½**:
- `rebuild_bm25()`: é‡å»ºBM25ç´¢å¼•
- é›†æˆ `smart_tokenize` è¿›è¡Œä¸­è‹±æ–‡æ™ºèƒ½åˆ†è¯

## ğŸš¨ å½“å‰æŠ€æœ¯éš¾ç‚¹ä¸æ”¹è¿›æ–¹å‘

### ğŸ”´ ä¼˜å…ˆçº§1: åˆ†å—ç²’åº¦ä¸å›¾è°±æå–ç²’åº¦ä¸ä¸€è‡´é—®é¢˜

**ç°çŠ¶é—®é¢˜**:
- **æ–‡æœ¬åˆ†å—**: ä½¿ç”¨SpacyTextSplitterï¼Œchunk_size=256å­—ç¬¦
- **å›¾è°±æå–**: æŒ‰å•ä¸ªchunkæå–çŸ¥è¯†å›¾è°±
- **ç²’åº¦å†²çª**: ä¸­è‹±æ–‡å¥å­é•¿åº¦å·®å¼‚å¯¼è‡´chunkåŒ…å«ä¿¡æ¯é‡ä¸ä¸€è‡´
- **ä»£ç æ‰§è¡Œ**ï¼šå†™äº†chunk_size=256ï¼Œä½†å®é™…æå–çš„æ—¶å€™è¿˜æ˜¯ä¼šæå–å‡ºè¿œè¶…256çš„æ–‡æœ¬å—ï¼Œå¯¼è‡´å›¾è°±æå–çš„ç²’åº¦éå¸¸ç²—ç³™

**å…·ä½“è¡¨ç°**:

```python
# text_utils.py å½“å‰å®ç°
def split_text(corpus: str, language="English", chunk_size=256, overlap=25):
    if language == "English":
        pipeline = "en_core_web_sm"  # è‹±æ–‡åˆ†è¯
    elif language == "Chinese":
        pipeline = "zh_core_web_sm"   # ä¸­æ–‡åˆ†è¯
    else:
        raise ValueError("æœªçŸ¥è¯­è¨€")
    splitter = SpacyTextSplitter(pipeline=pipeline, chunk_size=chunk_size, chunk_overlap=overlap)
    return splitter.split_text(corpus)
```

**é—®é¢˜åˆ†æ**:

1. **è¯­è¨€å·®å¼‚**: ä¸­æ–‡ä¿¡æ¯å¯†åº¦æ›´é«˜ï¼Œ256å­—ç¬¦ä¸­æ–‡ vs è‹±æ–‡åŒ…å«ä¸åŒä¿¡æ¯é‡
2. **æå–è´¨é‡**: chunkå¤ªå°â†’å›¾è°±è´¨é‡å¯ä»¥ä¿è¯ï¼Œä½†æ˜¯æˆ‘ç›®å‰çš„ä¸‰æ­¥æµæ°´çº¿è€—æ—¶å¤ªé•¿ï¼Œè€Œä¸”ä¸åŒchunkä¹‹é—´æ— æ³•æ²Ÿé€šï¼Œå¯èƒ½å¼•å‘ç›¸åŒå®ä½“åå¤å»ºèŠ‚ç‚¹ï¼Œä¸ºåç»­æ¶ˆæ­§å¢åŠ å·¥ä½œé‡ã€‚chunkå¤ªå¤§â†’å®ä½“å…³ç³»æ··ä¹±ï¼Œllmæå–ä¿¡æ¯ç²’åº¦å¤ªè¿‡äºç²—ç³™ï¼ŒæŸå¤±å¾ˆå¤šä¿¡æ¯ã€‚
3. **æŸ¥è¯¢å¯¹é½**: æ£€ç´¢æ—¶çš„chunkç²’åº¦ä¸å›¾è°±æ„å»ºç²’åº¦ä¸åŒ¹é…ï¼ŒæŸ¥è¯¢è´¨é‡ä¸é«˜ã€‚

**å¯èƒ½çš„æ”¹è¿›æ–¹æ¡ˆ**:ï¼ˆè¯·ä»”ç»†å®¡æŸ¥ï¼Œè¿™ä¸ªåªæ˜¯ä¸€ä¸ªåˆå­¦è€…æå‡ºæ¥çš„ï¼Œæˆ‘ä¸çŸ¥é“é ä¸é è°±ï¼Œæˆ‘è§‰å¾—ä¸å¤ªé è°±ï¼Œå› ä¸ºè¿™ä¸ªå¹¶æ²¡æœ‰è§£å†³å»ºå›¾çš„æ ¹æœ¬é—®é¢˜å’Œå†²çªï¼‰

```python
# å»ºè®®çš„è‡ªé€‚åº”åˆ†å—ç­–ç•¥
CHUNK_CONFIGS = {
    "Chinese": {
        "chunk_size": 200,      # ä¸­æ–‡ä¿¡æ¯å¯†åº¦é«˜ï¼Œé€‚å½“å‡å°
        "overlap": 30,
        "min_chunk_size": 50,   # æœ€å°chunkç¡®ä¿å›¾è°±è´¨é‡
    },
    "English": {
        "chunk_size": 320,      # è‹±æ–‡å¯ä»¥é€‚å½“å¢å¤§
        "overlap": 40,
        "min_chunk_size": 80,
    }
}
```

### ğŸ”µ ä¼˜å…ˆçº§2: å›¾è°±æ„å»ºä¸æŸ¥è¯¢ç²’åº¦å¯¹é½ï¼ˆæ ¸å¿ƒé—®é¢˜ï¼‰

**æ ¸å¿ƒé—®é¢˜**:
> å½“å‰æ„å»ºå›¾è°±çš„æ–¹å¼å’ŒæŸ¥è¯¢å›¾è°±çš„æ–¹å¼ï¼Œç²’åº¦å¯¹ä¸é½ï¼ŒæŸ¥è¯¢è™½ç„¶æŒ‡ä»¤éµå¾ªå¯ä»¥ï¼Œä½†æ˜¯å»ºçš„å›¾è°±è´¨é‡å¤ªå·®äº†

**é—®é¢˜æ ¹æºåˆ†æ**:

1. **æ„å»ºç²’åº¦é—®é¢˜**:
   ```python
   # å½“å‰Data2Neo4j.process()æ˜¯æŒ‰chunkæ„å»º
   def process(self, filename: str, text: str):
       # textæ˜¯å•ä¸ªchunkï¼Œä¿¡æ¯å¯èƒ½ä¸å®Œæ•´
       raw_triples_str = self._extract_raw_triples(text)
   ```

2. **æŸ¥è¯¢ç²’åº¦é—®é¢˜**:
   ```python
   # æŸ¥è¯¢æ—¶æœŸæœ›å®Œæ•´çš„å®ä½“å…³ç³»ç½‘ç»œ
   def query_graph_raw(self, question: str):
       # ä½†å›¾è°±æ˜¯ç¢ç‰‡åŒ–æ„å»ºçš„ï¼Œç¼ºä¹å…¨å±€è¿è´¯æ€§
   ```

**æ”¹è¿›ç­–ç•¥**:

**A. åˆ†å±‚å›¾è°±æ„å»ºï¼Œä½†æ˜¯é€»è¾‘ä¼šå¾ˆå¤æ‚ï¼Œéœ€è¦ç»è¿‡å’Œæˆ‘çš„è®¨è®º**:

```python
class LayeredGraphBuilder:
    def build_document_level_graph(self, filename: str, full_text: str):
        """æ–‡æ¡£çº§å›¾è°±ï¼šå…¨å±€å®ä½“è¯†åˆ«"""
        pass
    
    def build_chunk_level_graph(self, chunk: str, doc_entities: List[str]):
        """chunkçº§å›¾è°±ï¼šåŸºäºå·²è¯†åˆ«å®ä½“æå–å…³ç³»"""
        pass
    
    def merge_hierarchical_graphs(self):
        """åˆå¹¶å±‚æ¬¡åŒ–å›¾è°±"""
        pass
```

**B. å®ä½“IDè§„èŒƒåŒ–ï¼Œè¿™ä¸ªå¯èƒ½éœ€è¦åœ¨å›¾è°±å»ºç«‹çš„æ—¶å€™è®©llmå»ç»´æŠ¤**:

```python
# å»ºç«‹å®ä½“åˆ«åæ˜ å°„è¡¨
ENTITY_ALIASES = {
    "å›¾çµ": ["è‰¾ä¼¦Â·å›¾çµ", "Alan Turing", "A.M.Turing"],
    "è®¡ç®—æœº": ["ç”µå­è®¡ç®—æœº", "æ•°å­—è®¡ç®—æœº", "computer"]
}
```

**C. å…³ç³»æ ‡ç­¾ç™½åå•ï¼Œè¿™ä¸ªæ–¹æ¡ˆä¸å¤ªå¯è¡Œï¼Œæ¯•ç«Ÿéœ€è¦æ‰‹åŠ¨ç»´æŠ¤ï¼Œè€Œä¸”æˆ‘ä»¬ä¹Ÿæ²¡åŠæ³•æƒ³åˆ°æ‰€æœ‰åœºæ™¯**:

```python
# é™åˆ¶å…³ç³»ç±»å‹ï¼Œæé«˜å›¾è°±ä¸€è‡´æ€§
ALLOWED_RELATIONS = [
    "å‡ºç”Ÿäº", "æ­»äº", "å·¥ä½œäº", "å‘æ˜", "æå‡º", 
    "å‚ä¸", "å½±å“", "å¸ˆä»", "åˆä½œ", "åˆ›å»º"
]
```

### ğŸŸ¡ ä¼˜å…ˆçº§3: å¼‚æ­¥å¹¶å‘ä¼˜åŒ–

**ç°çŠ¶é—®é¢˜**:

- å½“å‰æ‰€æœ‰LLMè°ƒç”¨éƒ½æ˜¯åŒæ­¥çš„
- æ‰¹é‡æ–‡æ¡£å¤„ç†æ—¶æ•ˆç‡ä½ä¸‹
- å›¾è°±æ„å»ºè€—æ—¶è¿‡é•¿

**æ¶‰åŠæ¨¡å—**:

1. **Data2Neo4j**: å›¾è°±æå–çš„ä¸‰æ­¥æµæ°´çº¿å¯å¹¶å‘
2. **Embedder**: å‘é‡åµŒå…¥æ‰¹å¤„ç†å¯ä¼˜åŒ–

**æ”¹è¿›å»ºè®®**:

```python
# ç¤ºä¾‹ï¼šå¼‚æ­¥å¤šæŸ¥è¯¢ç”Ÿæˆ
async def expand_async(self, query: str, num_queries=3) -> List[str]:
    tasks = []
    for i in range(num_queries):
        task = asyncio.create_task(self._generate_single_query(query, i))
        tasks.append(task)
    results = await asyncio.gather(*tasks)
    return results
```

### ğŸŸ  ä¼˜å…ˆçº§4: æŸ¥è¯¢æ‰©å±•æç¤ºè¯ä¼˜åŒ–

**ç°åœ¨çš„æç¤ºè¯** (multiquery_generator.py):

```python
cypher_generation_prompt = f"""
        ä½ æ˜¯ä¸€åé«˜æ•ˆçš„ Neo4j Cypher æŸ¥è¯¢ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸¥æ ¼æ ¹æ®ä¸‹é¢æä¾›çš„â€œå¯ç”¨å·¥å…·â€å’Œç”¨æˆ·é—®é¢˜ï¼Œç”Ÿæˆä¸€æ®µ Cypher ä»£ç ã€‚
        1.  ä½¿ç”¨ `id` å±æ€§è¿›è¡ŒåŒ¹é…ã€‚
        2.  æŸ¥è¯¢å’Œreturnè¯­å¥ä¸­ï¼Œä¿æŒå˜é‡åä¸€è‡´ï¼ˆæ˜¯çš„ï¼Œè¿™ä¹ˆç®€å•çš„é”™è¯¯ä¹Ÿæœ‰å¯èƒ½çŠ¯ï¼‰ï¼›
        3.  èŠ‚ç‚¹æ ‡ç­¾å’Œå…³ç³»ç±»å‹**åªèƒ½**æ¥è‡ªåˆ—è¡¨é‡Œé¢æä¾›çš„å…ƒç´ ï¼Œç»å¯¹ä¸è¦è‡ªå·±ç¼–é€ åˆ—è¡¨é‡Œä¸å­˜åœ¨çš„è¯è¯­
        4.  çµæ´»æŸ¥è¯¢ï¼š
            æ ‡ç­¾ / å…³ç³»æ‰¹é‡åŒ¹é…ï¼šç”¨ æ ‡ç­¾1|æ ‡ç­¾2 æˆ– å…³ç³»1|å…³ç³»2 æˆ–å¤šä¸ª| è¦†ç›–å¤šç±»æ ‡ç­¾ / å…³ç³»ï¼Œå¦‚åŒ¹é… Person|Organization æ ‡ç­¾èŠ‚ç‚¹ã€æŸ¥è¯¢ published|wrote å…³ç³»ï¼›
            æ‰¹é‡å›ºå®šåŒ¹é…ï¼šç”¨ IN ['id1', 'id2', 'id3'] ä¸€æ¬¡æ€§åŒ¹é…å¤šä¸ªå·²çŸ¥ id çš„èŠ‚ç‚¹ï¼Œå¦‚åŒæ—¶æŸ¥è¯¢ â€œå›¾çµâ€â€œå¸ƒè±åˆ‡åˆ©åº„å›­â€ï¼›
            å‰ç¼€ / åç¼€åŒ¹é…ï¼šç”¨ STARTS WITH 'å‰ç¼€' æˆ– ENDS WITH 'åç¼€' ç²¾å‡†åŒ¹é… id å¼€å¤´ / ç»“å°¾çš„å†…å®¹ï¼Œå¦‚åŒ¹é… id ä»¥ â€œè‹±â€ å¼€å¤´çš„èŠ‚ç‚¹ã€‚
            æ¨¡ç³ŠåŒ¹é…ï¼šç”¨ =~ '.*å…³é”®è¯.*' åŒ¹é… id å«æŒ‡å®šå…³é”®è¯çš„èŠ‚ç‚¹ï¼›
        
        ### ä¸é—®é¢˜ç›¸å…³çš„ Schema å’Œå®ä½“:
        {context_for_prompt}
        ---
        **ç”¨æˆ·é—®é¢˜**: {question}
        ---
        ç›´æ¥è¾“å‡ºcypheræŸ¥è¯¢ï¼Œä¸è¦è¾“å‡ºå¤šä½™çš„å†…å®¹ã€‚
        """
```

- æˆ‘ä¸ªäººæ„Ÿè§‰è¿™ä¸ªæç¤ºè¯å·²ç»å†™çš„å¾ˆå¥½äº†ï¼Œæ— éœ€æ”¹åŠ¨ï¼Œæˆ–è€…ä½ å¯ä»¥æ ¹æ®â€œæŸ¥è¯¢çš„å¹¿æ³›ç¨‹åº¦â€æ’ä¸ªåºï¼Œæ”¹è¿™ä¸€æ®µæç¤ºè¯ä¹‹å‰ä¸€å®šè¦å’Œæˆ‘å…ˆè®¨è®ºã€‚æˆ–è€…æ˜¯å¼•å…¥é‚»å±…æŸ¥è¯¢ï¼Œé‚»å±…çš„é‚»å±…çš„æŸ¥è¯¢ä¹‹ç±»çš„ã€‚

**å¯èƒ½çš„æ”¹è¿›æ–¹æ¡ˆï¼Œå¤§ä½“æ„æ€** (åŸºäºé¡¹ç›®è§„èŒƒmemory):

```python
1. **åŒä¹‰æ”¹å†™**: ä½¿ç”¨ä¸åŒè¡¨è¾¾æ–¹å¼é‡è¿°åŸé—®é¢˜
2. **å®ä½“åˆ«å**: è€ƒè™‘å®ä½“çš„ä¸åŒç§°å‘¼æˆ–ç¿»è¯‘
3. **æœ¯è¯­æ‰©å±•**: æ‰©å±•ä¸“ä¸šæœ¯è¯­å’Œç›¸å…³æ¦‚å¿µ
4. **å­ä¸»é¢˜åˆ†è§£**: å°†å¤åˆé—®é¢˜åˆ†è§£ä¸ºå­æ–¹é¢
5. **å±æ€§æœºåˆ¶**: ä»ä¸åŒå±æ€§è§’åº¦æé—®
```

ä½†æ˜¯è¿™äº›æ–¹æ¡ˆä¸€å®šä¸è¦è®©æ¨¡å‹è‡ªå·±å»ç¼–é€ èŠ‚ç‚¹å…³ç³»å’Œè¾¹çš„ç±»å‹ï¼Œæˆ–è€…å¼•å…¥ä¸å­˜åœ¨çš„æ ‡ç­¾ï¼Œè¿™ä¸ªé—®é¢˜æˆ‘æ”¹çš„å¾ˆå¤´ç–¼ï¼Œä¸è¦å†çŠ¯äº†ã€‚æˆ‘ç›®å‰ç”¨çš„æ¨¡å‹æ˜¯DeepSeek-chatï¼Œè¿™ä¸ªæ¨¡å‹èƒ½åŠ›è¿˜æ˜¯å¯ä»¥çš„ã€‚

### ğŸŸ£ ä¼˜å…ˆçº§5: å¿«é€Ÿæµ‹è¯•ä¸å›å½’æœºåˆ¶

**é—®é¢˜**: 
> å»ºä¸€ä¸ªå›¾è°±æ—¶é—´å¤ªé•¿äº†ï¼Œéš¾ä»¥æµ‹è¯•ï¼Œå¯¼è‡´æœ€ç»ˆå›¾è°±æŸ¥è¯¢çš„è´¨é‡ä¹Ÿä¸é«˜

**è§£å†³æ–¹æ¡ˆ**:

**A. å°æ ·æœ¬å¿«é€Ÿæµ‹è¯•ï¼Œå¯ä»¥é‡‡ç”¨**:

```python
class QuickTester:
    def __init__(self):
        self.test_docs = [
            "å›¾çµ_ç®€ä»‹.md",  # 50è¡Œä»¥å†…çš„æµ‹è¯•æ–‡æ¡£
            "AI_åŸºç¡€.md"
        ]
    
    def quick_graph_test(self):
        """5åˆ†é’Ÿå†…å®Œæˆå›¾è°±æ„å»º+æŸ¥è¯¢æµ‹è¯•"""
        for doc in self.test_docs:
            # æ„å»ºå°å›¾è°±
            # æ‰§è¡Œæ ‡å‡†æŸ¥è¯¢é›†
            # è¯„ä¼°è´¨é‡æŒ‡æ ‡
            pass
```

**B. å›¾è°±è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼Œè¿™ä¸ªä¸œè¥¿åœ¨åç»­å¼€å‘ä¸­è€ƒè™‘ï¼Œå½“å‰æ˜¯å…ˆå®ç°ç¨³å®šçš„æŸ¥è¯¢**:

```python
def evaluate_graph_quality(self, test_queries: List[str]) -> Dict[str, float]:
    return {
        "entity_coverage": 0.0,    # å®ä½“è¦†ç›–ç‡
        "relation_accuracy": 0.0,  # å…³ç³»å‡†ç¡®æ€§
        "query_success_rate": 0.0, # æŸ¥è¯¢æˆåŠŸç‡
        "response_relevance": 0.0  # ç­”æ¡ˆç›¸å…³æ€§
    }
```

**C. å¢é‡æµ‹è¯•æœºåˆ¶ï¼ŒåŒæ ·ä¹Ÿæ˜¯åç»­ä¼˜åŒ–ç‚¹**:

```python
def incremental_test(self):
    """å¢é‡æ·»åŠ æ–‡æ¡£ï¼Œè§‚å¯Ÿå›¾è°±è´¨é‡å˜åŒ–"""
    quality_trends = []
    for i, doc in enumerate(self.test_docs):
        self.add_corpus(doc)
        quality = self.evaluate_graph_quality(self.standard_queries)
        quality_trends.append((i, quality))
    return quality_trends
```

### ğŸŸ£ ä¼˜å…ˆçº§6: åå¤„ç†é€»è¾‘ä¿®æ”¹

- å½“å‰åå¤„ç†ï¼Œä¾ç„¶é¢ä¸´ç€å®ä½“å¤ªå¤šã€è¾¹å¤ªå¤šå¯¼è‡´çš„llmæ·¹æ²¡åœ¨ä¿¡æ¯ä¸­çš„é—®é¢˜ï¼Œå¯èƒ½æ¶ˆæ­§æ“ä½œå¹¶ä¸ä¼šç”Ÿæ•ˆ
- å¯èƒ½ä¼šé‡‡ç”¨ç±»ä¼¼äºæŸ¥è¯¢æ—¶çš„ä¸‰æ­¥èµ°ç­–ç•¥ï¼Œä½†æ˜¯æˆ‘ä»¬éœ€è¦é¦–å…ˆåœ¨æŸ¥è¯¢æ­¥éª¤ä¸­éªŒè¯å¯è¡Œæ€§ã€‚

### ğŸŸ£ ä¼˜å…ˆçº§7: è€ƒè™‘å¼•å…¥å¤šæ¨¡æ€

- å‰æœŸé¡¹ç›®å‡†å¤‡å®Œå–„åï¼Œè€ƒè™‘å¼•å…¥å¤šæ¨¡æ€ï¼Œå¦‚å›¾ç‰‡å¯¹åº”çš„å›¾ç‰‡è§£ææ¨¡å‹ï¼Œå›¾ç‰‡çš„åµŒå…¥å’Œå›¾è°±çš„æ„å»ºï¼Œä»¥åŠpdfè§£æå™¨ã€latexå…¬å¼è§£æã€è¡¨æ ¼è§£æç­‰ç­‰ï¼Œæ¯”å¦‚è¯´å¯ä»¥å¼•å…¥minerUå·¥å…·ã€‚

### ğŸŸ£ ä¼˜å…ˆçº§8: ç³»ç»Ÿæ•´ä½“ä¼˜åŒ–

- å½“å‰è¿™ä¸ªé¡¹ç›®æ›´å¤šæ˜¯å±äºåŸå‹æ¼”ç¤ºï¼Œå°demoï¼Œæƒ³åšæˆçœŸæ­£å¯ç”¨çš„çš„è¯éœ€è¦æœ‰ä¸€ä¸ªç®€å•çš„å‰ç«¯UIï¼Œç„¶åéœ€è¦æ€§èƒ½ä¸Šçš„ä¼˜åŒ–ï¼Œæ‰“é€ ä¸€ä¸ªä¸ªäººæˆ–è€…ä¼ä¸šçœŸæ­£èƒ½ç”¨çš„ä¸œè¥¿ã€‚

## ğŸ” å…³é”®é…ç½®å‚æ•°

### æ–‡æœ¬å¤„ç†é…ç½®
```python
# text_utils.py
CHUNK_SIZE = 256        # å½“å‰å›ºå®šå€¼ï¼Œéœ€è¦æ”¹ä¸ºè¯­è¨€è‡ªé€‚åº”
CHUNK_OVERLAP = 25      # é‡å å¤§å°

# smart_tokenize.py  
MIN_TOKEN_LENGTH = 1    # æœ€å°tokené•¿åº¦ï¼Œå½±å“BM25æ•ˆæœ
```

### å›¾è°±æ„å»ºé…ç½®
```python
# Data2Neo4j.py
BATCH_SIZE = 100           # æ–‡æ¡£å—æ‰¹å¤„ç†å¤§å°ï¼Œè¿™ä¸ªæ˜¯ç¡¬æ€§è§„å®š
TEMPERATURE = 0.0          # LLMæ¸©åº¦ï¼Œå½±å“æå–ç¨³å®šæ€§
MAX_ENTITIES_PER_CHUNK = 10 # æ¯ä¸ªchunkæœ€å¤§å®ä½“æ•°ï¼ˆå»ºè®®æ–°å¢ï¼‰
```

### æ£€ç´¢é…ç½®  
```python
# retriever.py
RRF_K = 60              # RRFå¹³æ»‘å‚æ•°
DEFAULT_K = 10          # é»˜è®¤æ£€ç´¢æ•°é‡
DEFAULT_TOP_N = 4       # é‡æ’åºåä¿ç•™æ•°é‡
```

## ğŸ› å·²çŸ¥Issueä¸Workaround

### Issue 1: ä¸­æ–‡å•å­—ç¬¦å¹²æ‰°BM25
**ä½ç½®**: `smart_tokenize.py`
**é—®é¢˜**: ä¸­æ–‡åˆ†è¯äº§ç”Ÿå•å­—ç¬¦å½±å“BM25å‡†ç¡®æ€§
**ä¸´æ—¶æ–¹æ¡ˆ**: ä½¿ç”¨`len(token.strip()) >= 1`è¿‡æ»¤ï¼Œä½†ä»éœ€ä¼˜åŒ–

### Issue 2: Gemini APIæ‰¹é‡é™åˆ¶
**ä½ç½®**: `rag_system.py - add_corpus()`
**é—®é¢˜**: è¶…è¿‡100ä¸ªæ–‡æ¡£å—æ—¶APIæŠ¥é”™
**è§£å†³æ–¹æ¡ˆ**: å·²å®ç°batch_size=100åˆ†æ‰¹å¤„ç†

## ğŸ“š å¼€å‘è§„èŒƒ

### ä»£ç é£æ ¼
- ä½¿ç”¨ç±»å‹æ³¨è§£: `def query(self, query: str, k: int = 10) -> str`
- é”™è¯¯å¤„ç†: å…³é”®è·¯å¾„å¿…é¡»æœ‰try-catch

### æµ‹è¯•è§„èŒƒ
- æ¯ä¸ªæ–°åŠŸèƒ½éœ€è¦å¯¹åº”çš„æµ‹è¯•ç”¨ä¾‹
- å›¾è°±æ„å»ºåŠŸèƒ½éœ€è¦å°æ ·æœ¬å¿«é€Ÿæµ‹è¯•
- APIè°ƒç”¨éœ€è¦æ¨¡æ‹Ÿæµ‹è¯•é¿å…æ¶ˆè€—é¢åº¦

### æ–‡æ¡£æ›´æ–°
- æ–°å¢é…ç½®å‚æ•°éœ€è¦æ›´æ–°config.pyæ³¨é‡Š
- æ ¸å¿ƒç®—æ³•å˜æ›´éœ€è¦æ›´æ–°README.md
- é‡å¤§æ¶æ„è°ƒæ•´éœ€è¦æ›´æ–°æœ¬æ–‡æ¡£

---

**æœ€åæ›´æ–°**: 2025-10-07  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**ç»´æŠ¤è€…**: RAGå¼€å‘å›¢é˜Ÿ



# åç»­ä¼˜åŒ–æ–¹å‘ï¼ˆç°åœ¨ç«‹åˆ»é©¬ä¸Šçš„ï¼‰

1.åŠ ä¸Šå¯ä»¥æŒ‡å®šä¸åŒçš„çŸ¥è¯†åº“
2.ä¾ç„¶æ˜¯åˆ†å—ç²’åº¦å¤ªç²—äº†ï¼Œæå–è´¨é‡ä¹Ÿä¸é«˜
3.æ‰€æœ‰éœ€è¦å®ä½“çš„åœ°æ–¹å¯ä»¥å®‰æ’ä¸€ä¸ªæ’åº
4.**å±æ€§ä¸å¤Ÿä¸°å¯Œï¼ï¼ï¼ä¿¡æ¯ä¸å¤Ÿå¤š**
5.æ¶ˆæ­§æ²¡å‘æŒ¥ä½œç”¨
6.è¶…é•¿ä¸Šä¸‹æ–‡ï¼Œå¤šå¤„
7.raise self._make_status_error_from_response(err.response) from None  
openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 131072 tokens. Howe  
ver, you requested 156082 tokens (156082 in the messages, 0 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}



é¡¹ç›®æˆªæ­¢åˆ°ç°åœ¨ï¼Œçš„é—®ç­”ç¤ºä¾‹ï¼š

```
ï¼ˆå¾…å¡«å……ï¼‰
```


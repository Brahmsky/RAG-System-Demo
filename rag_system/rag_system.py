import os
from pathlib import Path
from google import genai
from openai import OpenAI
from neo4j import GraphDatabase

from .core.database import KnowledgeDatabase
from .text.retriever import Retriever
from .text.reranker import Reranker
from .generation.compressor import Compressor
from .generation.generator import Generator
from .utils.text_utils import TextProcessor
from .core.config import RAGConfig
from .text.multiquery_generator import MultiqueryGenerator
from .core.embedder import Embedder
from .graph.Data2Neo4j import Data2Neo4j

class RAGSystem:
    def __init__(self, config: RAGConfig):
        self.config = config
        ebd_client = genai.Client(api_key=config.gemini_api_key)
        llm_client = OpenAI(api_key=os.environ.get("DEEPSEEK_API_KEY"),
                                base_url='https://api.deepseek.com')
        neo_driver = {'uri': config.neo4j_uri,'auth': config.neo4j_auth}
        try:
            self.neo = Data2Neo4j(llm_client, config.llm_model_name, neo_driver)
        except Exception as e:
            raise RuntimeError(f"Neo4jåˆå§‹åŒ–å‡ºé”™ï¼š{str(e)}ï¼Œè¯·æ£€æŸ¥æœåŠ¡/é…ç½®ï¼")

        self.embedder = Embedder(ebd_client, config.embedding_model_name)
        # åˆå§‹åŒ–æ•°æ®åº“
        self.db = KnowledgeDatabase(
            db_path=config.db_path,
            collection_name=config.embedding_model_name.replace("/", "_"),
            verbose=config.verbose,
        )
        self.db.rebuild_bm25()

        query_expander = MultiqueryGenerator(llm_client, config.llm_model_name)

        # æ³¨æ„ï¼šè¿™é‡Œåº”è¯¥ä½¿ç”¨ config.embedding_model_nameï¼ˆå®ä¾‹å±æ€§ï¼‰ï¼Œè€Œä¸æ˜¯ RAGConfig.embedding_model_nameï¼ˆç±»å±æ€§ï¼‰
        # collection å·²ç»åœ¨ self.db åˆå§‹åŒ–æ—¶åˆ›å»ºäº†ï¼Œè¿™é‡Œæ˜¯é‡å¤è·å–ï¼ˆå¯ä»¥åˆ é™¤ï¼‰
        # collection_name = config.embedding_model_name.replace('/', '_')
        # self.collection = self.db.chroma_client.get_or_create_collection(name=collection_name)

        # åˆå§‹åŒ–æ¨¡å—
        self.retriever = Retriever(self.db, embedder=self.embedder, query_expander=query_expander, verbose=config.verbose)
        self.reranker = Reranker(config.reranker_model_name)
        self.compressor = Compressor(llm_client, config.llm_model_name, verbose=config.verbose)
        self.generator = Generator(llm_client, config.llm_model_name)

    # ================= çŸ¥è¯†åº“ç®¡ç† =================

    def add_corpus(self, filename: str, language="English"):
        """æ·»åŠ æ–°æ–‡æ¡£åˆ°çŸ¥è¯†åº“ - ä½¿ç”¨æ–‡æ¡£çº§å®ä½“è¯†åˆ«ä¼˜åŒ–å›¾è°±æ„å»º"""
        filepath = Path(self.config.knowledgebase_path) / filename

        print(f"å¼€å§‹å¤„ç†çŸ¥è¯†åº“æ–‡ä»¶ï¼š{filepath}")
        text = TextProcessor.read_file(filepath)
        chunks = TextProcessor.split_text(text, language=language)

        ids = [f"{filename}_{i}" for i in range(len(chunks))]
        existing_ids = set(self.db.collection.get(ids=ids)['ids'])
        print(f"åœ¨æ•°æ®åº“ä¸­æ‰¾åˆ°äº†{len(existing_ids)}ä¸ªå·²å­˜åœ¨çš„å—")

        new_docs, new_ids = [], []
        for i, doc in enumerate(chunks):
            if ids[i] not in existing_ids:
                new_docs.append(doc)
                new_ids.append(ids[i])
        if not new_docs:
            print("æ‰€æœ‰æ–‡æœ¬å—éƒ½å·²å®Œæˆå­˜äºæ•°æ®åº“ï¼Œæ— éœ€æ·»åŠ ã€‚\n")
            return

        print(f"å‘æ•°æ®åº“ä¸­æ·»åŠ {len(new_docs)}ä¸ªæ–°æ–‡æœ¬å—â€¦â€¦")
        
        # ========== ğŸ”¥ å…³é”®æ”¹è¿›ï¼šä½¿ç”¨æ–‡æ¡£çº§å¤„ç†æ–¹æ³• ==========
        # ä½¿ç”¨æ–°çš„process_documentæ–¹æ³•æ›¿ä»£é€chunkè°ƒç”¨process
        self.neo.process_document(filename, text, new_docs)
        
        # æ‰¹é‡ç”Ÿæˆ embedding
        batch_size = 100
        for i in range(0, len(new_docs), batch_size):
            batch = new_docs[i:i+batch_size]

            embeddings = self.embedder.embed(batch, task_type="RETRIEVAL_DOCUMENT")
            batch_ids = [f"{filename}_{i+j}" for j in range(len(batch))]
            metadatas = [{"source": filename} for _ in batch]

            self.db.collection.add(
                ids=batch_ids,
                documents=batch,
                embeddings=embeddings,
                metadatas=metadatas,
            )

        # æ‰§è¡Œåå¤„ç†åˆå¹¶
        self.neo.after_processing()

        self.db.rebuild_bm25()
        print(f"æ–‡æ¡£ {filename} æ·»åŠ å®Œæˆ âœ…")

    def remove_corpus(self, filename: str):
        """ä»çŸ¥è¯†åº“ä¸­åˆ é™¤æŒ‡å®šæ–‡æ¡£"""
        if self.config.verbose:
            print(f"æ­£åœ¨åˆ é™¤æ–‡æ¡£ {filename}â€¦")

        results = self.db.collection.get(where={"source": filename})
        ids = results["ids"]
        if ids:
            self.db.collection.delete(ids=ids)

        self.neo.delete_graph_from_sources(filename)

        self.db.rebuild_bm25()
        if self.config.verbose:
            print(f"æ–‡æ¡£ {filename} åˆ é™¤å®Œæˆ âœ…")

    def update_corpus(self, filename: str, language="English"):
        """æ›´æ–°çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£ï¼ˆå…ˆåˆ é™¤å†æ·»åŠ ï¼‰"""
        if self.config.verbose:
            print(f"æ­£åœ¨æ›´æ–°æ–‡æ¡£ {filename}â€¦")

        self.remove_corpus(filename)
        self.add_corpus(filename, language=language)

        if self.config.verbose:
            print(f"æ–‡æ¡£ {filename} æ›´æ–°å®Œæˆ âœ…")

    # ================= ä¸»æŸ¥è¯¢æ¥å£ =================

    def query(self, query: str, k=10, top_n=4, mode="hybrid", compress=False, source_filter=None) -> str:
        """ç»Ÿä¸€æŸ¥è¯¢æ¥å£"""
        text_docs = []
        graph_context = ""
        if mode in ["vector", "keyword", "expand", "text_hybrid"]:
            if mode == "vector":
                text_docs = self.retriever.vector_search(query, k, source_filter=source_filter)
            elif mode == "keyword":
                text_docs = self.retriever.keyword_search(query, k)
            elif mode == "expand":
                text_docs = self.retriever.expand_search(query, k, source_filter=source_filter)
            elif mode == "text_hybrid":
                text_docs = self.retriever.text_hybrid_search(query, k, source_filter=source_filter)

            if text_docs:
                text_docs = self.reranker.rerank(query, text_docs, top_n)
                if compress:
                    text_docs = self.compressor.compress(query, text_docs)
            else:
                return "æ–‡æœ¬ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

        elif mode == "graph":
            graph_context = self.neo.query_graph_raw(query)
            graph_context = graph_context if graph_context else "çŸ¥è¯†å›¾è°±ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

        elif mode == "hybrid": # é»˜è®¤æ¨¡å¼
            text_docs = self.retriever.text_hybrid_search(query, k, source_filter=source_filter)
            if text_docs:
                text_docs = self.reranker.rerank(query, text_docs, top_n)
                if compress:
                    text_docs = self.compressor.compress(query, text_docs)

            graph_context = self.neo.query_graph_raw(query)
            graph_context = graph_context if graph_context else "çŸ¥è¯†å›¾è°±ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

        else:
            return "Unknown search mode!"

        if not text_docs and (not graph_context or "æœªæ‰¾åˆ°" in graph_context):
            return "æ–‡æœ¬å’ŒçŸ¥è¯†å›¾è°±ä¸­å‡æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

        return self.generator.generate(query, text_docs, graph_context)